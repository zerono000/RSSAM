data:
  root_dir: "./data/WHU"  # 数据集根目录
  input_size: 1024    # 输入尺寸
  num_workers: 5      # 数据加载工作线程数

dataset:
  num_classes: 2
  class_names: ['背景', '建筑']
  binary_mode: true  # 可选，默认情况下num_classes=2时自动启用

model:
  # SAM配置
  sam_type: "vit_h"  # 选项: vit_b, vit_l, vit_h
  checkpoint: "sam_vit_h_4b8939.pth"
  freeze_image_encoder: true
  # max_foreground_queries: 10
  
  # 特征聚合器配置
  feature_layers: [0, 4, 8, 12, 16, 20, 24, 28, 31]  # 每隔4层选择一个ViT层
  out_channels: 32  # 输出通道数
  
  # 查询提示器配置
  num_points_per_query: 5  # 每个查询的提示点数量
  num_encoder_layers: 3
  num_decoder_layers: 6
  num_queries: 15  # 对象查询数量
  hidden_dim: 256
  dropout: 0.1
  
  # 梯度模块配置
  use_gradient: true
  # 掩码编码器配置
  use_coarse_mask: true

  # 新增分割框架配置
  segmentation_type: "semantic"  # 可选: "instance", "semantic"
  use_mask_attention: true  # 是否使用掩码注意力机制
  max_foreground_queries: 15
  memory_efficient: true  # 使用内存优化模式
  mask_attention_iterations: 2  # 掩码注意力迭代次数
  mask_attention_threshold: 0.5  # 掩码二值化阈值
  
postprocessing:
  score_threshold: 0.5  # 类别置信度阈值
  mask_threshold: 0.5   # 掩码二值化阈值

training:
  batch_size: 2
  lr: 0.0001
  weight_decay: 0.0001
  epochs: 300
  lr_drop: 200
  gradient_accumulation_steps: 4
  
  # 损失权重
  loss_weights:
    class_loss_coef: 5.0
    mask_loss_coef: 5.0
    dice_loss_coef: 5.0
    prompt_loss_coef: 1.0

  ddp_optimization:
    master_weights_only: true  # 仅在主进程保存模型权重
    broadcast_buffers: false   # 禁用缓冲区广播以提高性能

distributed:
  sync_bn: true             # 是否使用同步批量归一化
  find_unused_parameters: true  # 是否查找未使用的参数(用于复杂模型)
  gradient_as_bucket_view: true # 优化内存使用
  backend: 'nccl'           # 分布式通信后端，NVIDIA GPU推荐使用nccl


